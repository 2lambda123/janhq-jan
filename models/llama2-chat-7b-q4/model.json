{
    "source": [
      {
        "filename": "llama-2-7b-chat.Q4_K_M.gguf",
        "url": "https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_K_M.gguf"
      }
    ],
    "id": "llama2-chat-7b-q4",
    "object": "model",
    "name": "Llama 2 Chat 7B Q4",
    "version": "1.0",
    "description": "This is a 4-bit quantized iteration of Meta AI's Llama 2 Chat 7b model, specifically designed for a comprehensive understanding through training on extensive internet data.",
    "format": "gguf",
    "settings": {
      "ctx_len": 4096,
      "prompt_template": "[INST] <<SYS>>\n{system_message}<</SYS>>\n{prompt}[/INST]",
      "llama_model_path": "llama-2-7b-chat.Q4_K_M.gguf"
    },
    "parameters": {
      "max_tokens": 4096
    },
    "metadata": {
      "author": "MetaAI, The Bloke",
      "tags": ["7B", "Foundational Model"],
      "size": 4080000000
    },
    "engine": "nitro"
  }
  
