{
  "object": "model",
  "version": 1,
  "format": "gguf",
  "sources": [
    {
      "url": "https://huggingface.co/lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q5_K_M.gguf",
      "filename": "Meta-Llama-3-8B-Instruct-Q5_K_M.gguf"
    }
  ],
  "id": "llama-3-8b-instruct-q5",
  "name": "Llama 3 8B instruct q5",
  "created": 1713471717323,
  "description": "",
  "settings": {
    "ctx_len": 8000,
    "embedding": false,
    "prompt_template": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\n{system_message}<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n{prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
    "llama_model_path": "Meta-Llama-3-8B-Instruct-Q5_K_M.gguf"
  },
  "parameters": {
    "temperature": 0.7,
    "top_p": 0.95,
    "stream": true,
    "max_tokens": 2048,
    "stop": ["<|end_of_text|>","<|eot_id|>"],
    "frequency_penalty": 0.5,
    "presence_penalty": 0
  },
  "metadata": {
    "size": 5733500128,
    "author": "User",
    "tags": []
  },
  "engine": "nitro"
}